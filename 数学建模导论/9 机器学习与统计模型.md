# 9 机器学习与统计模型
## 9.1 统计分布与假设检验
### 9.1.1 统计量与常见统计分布
+ 概率和统计是一对孪生兄弟，**前者通过已知总体的所有相关参数信息，来计算特定事件发生的概率**；**后者则是在总体未知的情况下，通过采样观察样本状态来反推估计总体**。因此，尽管概率论中也有随机变量和分布律，数理统计中的统计分布与其仍然存在较大差别。但数理统计中统计量和分布的概念仍然需要借助概率论中的工具来研究。

+ ![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724092530.png)
+ 很显然，小球应该是落到最中间的格子的概率最大。这是理论情况下，可以绘制出不同格点的概率的条形图。现在从这个分布中采样，采集100个小球，每个小球都会依照分布掉落到一个格子内。如图所示。![9.1.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/9.1.png)
+ 从图中可以看到，很显然，小球所呈现的条形图并不是一个对称图形，而理论上的概率条形图应该是严格对称的，这也就展示了：样本与总体并不完全一致。但如果仔细对比，可以发现，样本的频率分布直方图和理论上的概率条形图相差并不太大，因此可以用样本来估计总体。对于每一格而言，条形的高度反映了落在这一格点的小球数量或者频率。把这样的能够反映样本频率在不同区间内分布状况的图像叫频率分布直方图。而如果使用更大的道尔顿板，底部格点更多的话，所得到频率分布直方图也更加光滑、更加接近于理论上的概率分布，可以用一条曲线去拟合这个频率分布直方图。这样的曲线其实也就是概率密度曲线。
+ 从上面的例子看来，实际样本的统计量也会呈现出特定的分布。但统计量的分布由于存在多个样本，它与单个随机变量的分布又是有着很大差异的。常见的统计分布包括下面四种：
	+ **正态分布**：![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724095005.png)
	+ **卡方分布**：![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724095025.png)
	+ **t-分布**：![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724095048.png)
	+ **F-分布**：![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724095111.png)
+ 事实上，不仅是整体分布，上面的四种分布都存在对应的概率密度曲线图。通过概率密度曲线图能够分析这些分布的性质。几种分布的概率密度曲线如图所示：![9.2.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/9.2.png)
+ 图中展示了正态分布、卡方分布、t分布和F分布四种分布的概率密度函数。正态分布曲线呈现出钟形形状，且关于均值对称。曲线下的面积表示概率，总面积为1。均值影响曲线对称轴，均值越大则曲线越偏右，而若标准差越大曲线最高点则越低。卡方分布曲线随着自由度的增加而逐渐趋近于正态分布。在自由度较小时，曲线呈现偏态特征，而在自由度较大时，曲线接近对称。随着自由度的增加，曲线的形状逐渐变得对称和稳定。t分布曲线随着自由度的增加而逐渐趋近于正态分布。在自由度较小时，曲线呈现出更宽的尾部和更尖的峰部，表现出更强的离散性。随着自由度的增加，曲线的形状逐渐变得平滑，并接近正态分布。F分布曲线在分母自由度较小或分子自由度较大时，曲线呈现出更窄的峰部和更长的尾部，表现出更强的离散性。随着分母自由度的增加，曲线的形状逐渐变得平滑。


### 9.1.2 正态性检验
+ 正态性检验的目的是为了检测一组数据是否服从正态分布，是否表现出正态分布的特性。正态性检验的方法有很多，包括QQ图、KS检验、SW检验、JB检验等等。这里当然不可能把它们全部讲出来，但可以对一些常见方法进行简要介绍：
	+ **Shapiro-Wilk检验**![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724101314.png)
	+ **K-S检验**![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724101353.png)
	+ **J-B检验**![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724101443.png)
	+ **QQ图**![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724101518.png)
+ 我们可以通过下面一个例子展示如何去进行正态性检验。首先，通过numpy生成一组服从标准正态分布的样本，这里将样本量扩充到1000个：
```python
import numpy as np  

import matplotlib.pyplot as plt  

# 生成标准正态分布的数据  

data = np.random.normal(0, 1, 1000)  

#Python绘制QQ图的方法集成在statsmodels当中，通过如下方式调用：

import statsmodels.api as sm

import matplotlib.pyplot as plt

# 创建 Q-Q 图，并增加 45度线

fig = sm.qqplot(data, line='45')

plt.show()
```
![9.3.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/9.3.png)
+ 从图中可以看到，蓝色散点表示样本取值与理论分布的关系，横坐标为理论分布的各个分位点，而纵坐标为样本分位点，它们近似分布在一条直线附近，因此可以初步判断它们服从正态分布。但这只是一种现象，是否真的服从正态分布还是要通过假设检验说明。
+ 正态性检验的方法集成在scipy.stats当中。以Shapiro-Wilk检验为例，通过在scipy.stats中引入shapiro方法，对上述样本检验如下：
```python
import scipy.stats as st

# 执行Shapiro-Wilk正态性检验

statistic, p_value = st.shapiro(data)

# 输出检验结果

print("Shapiro-Wilk统计量:", statistic)

print("p-value:", p_value)
```
+ 得到Shapiro-Wilk统计量等于 0.9973，概率值0.098>0.05，无法拒绝原假设。因此，认为数据data具备正态性。同样的，还可以进行K-S检验和J-B检验：
```python
statistic_1, p_value_1 = st.kstest(data,'norm')

# 输出检验结果

print("K-S统计量:", statistic_1)

print("p-value:", p_value_1)

statistic_2, p_value_2 = st.jarque_bera(data)

# 输出检验结果

print("J-B统计量:", statistic_2)

print("p-value:", p_value_2)
```
+ 得到的结果概率也都超过0.05，认为数据是服从正态分布的。在kstest函数中，如果要使用它进行正态性检验，要在后面的参数里选择’norm’表明需要做的检验是正态性检验。

### 9.1.3 独立性检验
https://datawhalechina.github.io/intro-mathmodel/#/CH9/%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B?id=_913-%e7%8b%ac%e7%ab%8b%e6%80%a7%e6%a3%80%e9%aa%8c
### 9.1.4 两组样本的差异性检验
+ 两组样本的差异性检验可以通过_t_-检验实现。T-检验分为三种不同的类型：单样本t检验、配对样本t检验和独立样本t检验。其中，单样本t检验解决的是检验正态性的问题，这里主要讨论配对样本t检验和独立样本t检验。![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724101928.png)
+ 差异性检验的原假设H0认为：两类样本之间没有差异。同样可以通过Python中的scipy.stats包调用函数求解，使用ttest_rel进行配对样本t检验，使用ttest_ind进行独立样本t检验。例如，现在有三组数据要进行差异性检验，它们的使用方法形如：
```python
from scipy.stats import ttest_rel,ttest_ind

import numpy as np

# 假设有三组样本的数据  

data1 = np.random.normal(10,5,100)

data2 = np.random.normal(12,6,100)

data3 = np.random.normal(10,5,55)

# 执行配对样本t检验  

t_statistic_1, p_value_1 = ttest_rel(data1, data2)   

# 输出结果  

print('t统计量:', t_statistic_1)  

print('p值:', p_value_1)

# 执行独立样本t检验  

t_statistic_2, p_value_2 = ttest_ind(data1, data3)   

# 输出结果  

print('t统计量:', t_statistic_2)  

print('p值:', p_value_2)
```
+ 在上面的案例中，data1和data2构成了配对样本关系，data1和data3是服从同一正态分布的两组独立样本。对二者同样分析概率大小就可以确定是否有差异了。一般来讲，如果概率比较小（至少小于0.05）可以认为拒绝原假设接受备择假设，认为两类样本有差异。可以看到，配对样本t检验的概率为0.019<0.05，两组数据存在明显的均值差异；而独立样本t检验概率为0.42，不拒绝原假设，认为独立样本之间不存在显著差异。

+ **注意**：t检验之前需要分析数据是否满足方差齐性，这一检验通过莱文检验实现。
	+ **莱文检验（Levene's test）** 是一种用于检验两组数据方差是否相等的统计检验方法。它的基本思想是比较两组数据的变异程度，如果两组数据的方差相等，那么它们的变异程度应该相似。如果两组数据的方差不相等，则它们的变异程度可能会有显著差异。在进行t检验之前进行莱文检验的原因是，t检验的前提假设是两个样本的方差相等。如果这个假设不成立，t检验的结果可能会受到方差不等的影响，导致错误的结论。因此，在进行t检验之前，需要进行莱文检验来检验两个样本的方差是否相等。代码形如：
```python
from scipy.stats import levene

# 执行莱文检验  

w, p = levene(data1, data2)  

# 输出结果  

print('W统计量:', w)  

print('p值:', p)
```
+ 在上述代码中，stats.levene()函数用于执行莱文检验。该函数返回两个值：W统计量和p值。W统计量越小，说明两组数据的方差越接近相等；p值越接近0，说明拒绝原假设（即两组数据的方差相等）的证据越强。通常情况下，如果p值小于设定的显著性水平（例如0.05），则认为两组数据的方差不相等，需要进一步分析或处理。
### 9.1.5 方差分析与事后多重比较
https://datawhalechina.github.io/intro-mathmodel/#/CH9/%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B?id=_915-%e6%96%b9%e5%b7%ae%e5%88%86%e6%9e%90%e4%b8%8e%e4%ba%8b%e5%90%8e%e5%a4%9a%e9%87%8d%e6%af%94%e8%be%83

### 9.1.6 相关系数
+ ![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240724102213.png)

## 9.2 回归不止用于预测
### 9.2.1 从统计的视角看线性回归
[[3 线性回归]]
### 9.2.2 逻辑回归
[[4 逻辑回归]]

### 9.2.3 分位数回归
### 9.2.4 调节效应与中介效应
### 9.2.5 路径分析法与结构方程
### 9.2.6 内生性问题与因果推断

## 9.3 Scipy与Statsmodels完成统计建模
+ https://datawhalechina.github.io/intro-mathmodel/#/CH9/%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%9E%8B?id=_93-%e4%bd%bf%e7%94%a8scipy%e4%b8%8estatsmodels%e5%ae%8c%e6%88%90%e7%bb%9f%e8%ae%a1%e5%bb%ba%e6%a8%a1

## 9.4 机器学习
[[1 机器学习简介]]
[[0 吴恩达机器学习ML]]

## 9.5 Sklearn与机器学习
[[0 引言]]

## 9.6 深度学习
[[0 吴恩达深度学习]]
[[0 李宏毅深度学习(DataWhale)]]


