# 10 多模数据与智能模型
+ 关键词：
	+ 数字图像处理与计算机视觉
	- 计算语言学与自然语言处理
	- 数字信号处理与智能感知
## 10.1 数字图像处理与计算机视觉
### 10.1.1 数字图像的表示与处理
+ Pytorch也可以实现OPENCV的部分功能：[[2 Pytorch加载数据]]
+ 计算机可以存储数字图像，可以展示数字图像，也可以对图像进行分析与处理。但一张图是怎样放到计算机中的呢？其实本质上还是依靠线性代数这个工具。计算机把数字图像看作一个很大的矩阵，把图像中每个像素看作矩阵的一个元素，用矩阵元素的值表示图像对应位置的像素点明暗程度以及颜色情况。
+ 我们可以通过opencv来实现图像处理的Python编程。OpenCV是一个开源的计算机视觉库。它包含了大量图像和视频处理的通用算法，比如图像滤波、特征检测、目标跟踪、人脸识别等。对于想要做图像处理或计算机视觉研究、开发的人来说，OpenCV就像一个强大的工具箱，能帮助他们更轻松、高效地实现各种复杂的视觉任务。无论你是做科学研究、商业应用还是个人项目，OpenCV都能为你提供很大的帮助。例如，读取项目中的一张图并展示，可以用如下代码表示：
```python
# These imports let you use opencv

import cv2 #opencv itself

import common #some useful opencv functions

import numpy as np # matrix manipulations

# the following are to do with this interactive notebook code

%matplotlib inline 

from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks

import pylab # this allows you to control figure size 

pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook

input_image=cv2.imread('noidea.jpg')

input_image=cv2.imread('noidea.jpg')
```
![wps1.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps1.jpg)
+ 查看这张图片的尺寸：
```python
print(input_image.shape)

结果为(414,625,3)，表明图像的大小为414*625，有三个通道。在这张图里面，有b,g,r三个通道。可以将它作分解并重新组合，我们来看看一个通道究竟长什么样子：

# split channels

b,g,r=cv2.split(input_image)

plt.imshow(r, cmap='gray')

merged=cv2.merge([r,g,b])

# merge takes an array of single channel matrices

plt.imshow(merged)
```
![wps2.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps2.jpg)
+ 可以看到，每个通道的图都可以当做一张单独的黑白图像，但经过rgb重排以后的图终于可以显示为正常的彩色。这一操作也可以用下面的代码实现：
```python
opencv_merged=cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)

plt.imshow(opencv_merged)
```
+ HSV表示法是一种描述颜色的方式，其中H代表色调（Hue），S代表饱和度（Saturation），V代表明度（Value）。这种颜色空间与人类对颜色的感知方式更为接近，因此，在图像处理中，HSV空间经常用于颜色分割、颜色识别等任务。
+ 色调是颜色的一种属性，它表示的是纯色的类型，比如红色、蓝色或黄色等。在HSV颜色空间中，色调以角度来表示，从0到360度。比如0（或360）度表示红色，120度表示绿色，240度表示蓝色。饱和度表示颜色的纯度或强度。一个颜色的饱和度越高，它就越鲜艳；饱和度越低，颜色就越接近灰色。在HSV中，饱和度是一个百分比值，从0%（灰色）到100%（完全饱和）。明度表示颜色的亮度或明暗程度。它与颜色的强度或发光量有关。在HSV中，明度也是一个百分比值，从0%（黑色）到100%（白色）。
+ RGB是一种加色模型，它是通过红、绿、蓝三种颜色的组合来表示颜色的。每种颜色的强度都通过一个0-255的数值来表示。RGB模型在显示设备上使用得很广泛，但它不太直观地表示人类对颜色的感知，尤其是色调。而HSV则是一种更接近人类感知的颜色空间，更适合用于颜色分割等任务。
+ 在OpenCV中，你可以使用cvtColor函数将图像从RGB空间转换到HSV空间。以下是一个简单的示例：
```python
# 读取图像  

image = cv2.imread('path_to_your_image.jpg')  

# 将图像从RGB转换到HSV  

hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)   

# 在HSV空间中设置一个颜色范围（比如蓝色）  

lower_blue = np.array([110, 50, 50])  

upper_blue = np.array([130, 255, 255])  

# 创建一个掩码，只保留在指定颜色范围内的像素  

mask = cv2.inRange(hsv_image, lower_blue, upper_blue)   

# 使用掩码对原图像进行颜色分割  

result = cv2.bitwise_and(image, image, mask=mask)   

# 显示结果  

cv2.imshow('Original Image', image)  

cv2.imshow('Mask', mask)  

cv2.imshow('Result', result)  

cv2.waitKey(0)  

cv2.destroyAllWindows()
```
+ 这段代码首先读取一个图像，然后将其从RGB空间转换到HSV空间。接着，它定义了一个蓝色的HSV范围，并创建了一个掩码，只保留在这个范围内的像素。最后，它使用这个掩码对原图像进行颜色分割，并显示结果。
+ 使用Opencv实现图像的裁剪可以通过数组索引的方式实现，例如，可以通过下面的代码切分图像中的某个部分：
```python
dogface = input_image[60:250, 70:350]

plt.imshow(dogface)
```
+ 我们还可以把切分出来的部分粘贴到原图上去：
```python
fresh_image=cv2.imread('noidea.jpg') 

fresh_image[200:200+dogface.shape[0], 200:200+dogface.shape[1]]=dogface

print(dogface.shape[0])

print(dogface.shape[1])

plt.imshow(fresh_image)

如果想要实现翻转，可以使用flip函数。通过axis参数控制是水平翻转还是竖直翻转：

flipped_code_0=cv2.flip(input_image,0) # vertical flip

plt.imshow(flipped_code_0)

和numpy.array类似，opencv也提供了数组转置的transpose函数，这被用于翻转行列并生成镜像效果：

transposed=cv2.transpose(input_image)

plt.imshow(transposed)
```
+ **高斯平滑（Gaussian Blurring）** 是图像处理中常用的一种技术，用于减少图像噪声和细节层次。它通过对图像中的每一个像素点，取其本身和邻域内的其他像素点的加权平均值来实现平滑效果。权重由高斯函数计算得出，距离中心越远的像素点，权重越小。可以通过GaussianBlur实现高斯平滑的效果：
```python
d=5

img_blur5 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]

plt.imshow(cv2.cvtColor(img_blur5, cv2.COLOR_BGR2RGB))
```
+ **腐蚀操作**是一种形态学操作，它用来消除图像中的小物体、断开连接在一起的物体等。腐蚀操作的基本思想是将结构元素在图像上滑动，如果结构元素下的所有像素都是前景像素（通常为白色），则该位置的中心像素被认为是前景像素，否则为背景像素。
```python
import cv2 

import numpy as np 

 

# 读取图像，转换为灰度图像  

image = cv2.imread('path_to_your_image.jpg', 0)  

 

# 定义结构元素（核），这里使用5x5的矩形核  

kernel = np.ones((5, 5), np.uint8)  

 

# 进行腐蚀操作  

eroded_image = cv2.erode(image, kernel, iterations=1)  

 

# 显示原图像和腐蚀后的图像  

cv2.imshow('Original Image', image)  

cv2.imshow('Eroded Image', eroded_image)  

cv2.waitKey(0)  

cv2.destroyAllWindows()
```
+ **锐化操作**是一种用于增强图像边缘和细节的技术。在OpenCV中，通常通过使用滤波器来实现锐化，比如拉普拉斯滤波器或者自定义的卷积核。
```python
import cv2 

import numpy as np  

# 读取图像  

image = cv2.imread('path_to_your_image.jpg')  

# 定义锐化卷积核  

kernel = np.array([[-1,-1,-1],  

          [-1,9,-1],  

          [-1,-1,-1]])  

# 应用卷积核进行锐化  

sharpened_image = cv2.filter2D(image, -1, kernel)  

# 显示原图像和锐化后的图像  

cv2.imshow('Original Image', image)  

cv2.imshow('Sharpened Image', sharpened_image)  

cv2.waitKey(0)  

cv2.destroyAllWindows()
```

### 10.1.2 数字图像的特征点
+ 特征点是数字图像处理中用于图像分析和处理的关键信息点，它们可以代表图像中的显著特征，如角点、边缘和其他结构。有效的特征点检测是很多计算机视觉任务的基础，包括图像匹配、物体识别和追踪等。
+ **Sobel特征点**主要基于Sobel算子，这是一种常用于边缘检测的算子。其核心思想是将图像分成水平和垂直两个方向，然后在每个方向上计算梯度并求和，最后将两个方向上的梯度幅值差作为边缘强度。Sobel特征点的计算方法主要是通过应用两个3x3的卷积核对图像进行卷积操作，分别计算图像在水平和垂直方向上的梯度变化，从而识别出图像中的边缘。其主要作用是用于边缘检测，能够突出图像中的边缘特征，有效减少数据量，保留图像的重要结构属性，为后续图像处理和分析提供基础。例如：
```python
sobelimage=cv2.cvtColor(input_image,cv2.COLOR_BGR2GRAY)

 

sobelx = cv2.Sobel(sobelimage,cv2.CV_64F,1,0,ksize=9)

sobely = cv2.Sobel(sobelimage,cv2.CV_64F,0,1,ksize=9)

plt.imshow(sobelx,cmap = 'gray') 
```
![wps4.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps4.jpg)

+ Canny算子是由John F. Canny于1986年开发出来的一个多级边缘检测算法，被认为是最好的边缘检测算法之一。它采用了一系列步骤来提取图像中的边缘信息，包括噪声抑制、梯度计算、非极大值抑制、双阈值检测以及边缘连接。
+ 首先，Canny算子利用高斯滤波器对输入图像进行平滑处理，以减少图像中的噪声。然后，通过对平滑后的图像应用Sobel或Prewitt等算子，计算每个像素点的梯度幅值和方向。接下来，非极大值抑制过程会在梯度图像上比较每个像素点在其梯度方向上的值，并保留局部最大值点，抑制非边缘像素。之后，Canny算子使用双阈值检测，根据设定的高阈值和低阈值，将梯度图像中的像素点分为强边缘、弱边缘和非边缘三个部分。最后，通过连接强边缘像素和与之相连的弱边缘像素，形成完整的边缘。
+ Canny算子相比其他边缘检测算法具有更高的准确性和更低的错误率，能够产生单一像素宽度的边缘响应，并尽量减少将噪声和细节等误判为边缘的情况。同时，Canny算子提出的基于边缘梯度方向的非极大值抑制和双阈值的滞后阈值处理，改进了传统算子如Sobel和Prewitt等的不足。
```python
th1=30

th2=60 # Canny recommends threshold 2 is 3 times threshold 1 - you could try experimenting with this...

d=3 # gaussian blur

 

edgeresult=input_image.copy()

edgeresult = cv2.GaussianBlur(edgeresult, (2*d+1, 2*d+1), -1)[d:-d,d:-d]

gray = cv2.cvtColor(edgeresult, cv2.COLOR_BGR2GRAY)

edge = cv2.Canny(gray, th1, th2)

edgeresult[edge != 0] = (0, 255, 0) # this takes pixels in edgeresult where edge non-zero colours them bright green

plt.imshow(cv2.cvtColor(edgeresult, cv2.COLOR_BGR2RGB))
```

![wps5.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps5.jpg)
+ Harris角点检测是一种计算机视觉中常用的角点检测算法，用于在图像中检测出角点特征。角点通常被定义为两条边的交点，或者说，角点的局部邻域应该具有两个不同区域的不同方向的边界。
+ Harris角点检测的原理主要基于图像的灰度变化和局部窗口的协方差矩阵。具体步骤包括：首先，将彩色图像转换为灰度图像；然后，根据灰度值计算每个像素的梯度，通常使用Sobel算子；接着，计算每个像素周围窗口内梯度的自相关矩阵；最后，根据自相关矩阵计算Harris响应函数，用于评估每个像素周围区域是否为角点。当Harris响应函数的值较大时，表示该像素点处存在角点。
+ Harris角点检测具有对图像旋转、尺度变化和亮度变化的不变性，且计算简单快速。它在计算机视觉领域中有广泛的应用，如目标跟踪、运动检测、视频剪辑、三维建模以及目标识别等。通过结合图像的多个角度，Harris角点检测可以恢复图像的完整形状，从而准确地识别和追踪目标。
```python
harris_test=input_image.copy()

#greyscale it

gray = cv2.cvtColor(harris_test,cv2.COLOR_BGR2GRAY)

 

gray = np.float32(gray)

blocksize=4 # 

kernel_size=3 # sobel kernel: must be odd and fairly small

# run the harris corner detector

dst = cv2.cornerHarris(gray,blocksize,kernel_size,0.05) # parameters are blocksize, Sobel parameter and Harris threshold

#result is dilated for marking the corners, this is visualisation related and just makes them bigger

dst = cv2.dilate(dst,None)

#we then plot these on the input image for visualisation purposes, using bright red

harris_test[dst>0.01*dst.max()]=[0,0,255]

plt.imshow(cv2.cvtColor(harris_test, cv2.COLOR_BGR2RGB))
```

![wps6.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps6.jpg)
+ ORB（Oriented FAST and Rotated BRIEF）特征点是一种快速且高效的局部特征点提取和描述方法，它结合了FAST特征点检测算法和BRIEF描述子算法，并通过一系列改进和融合实现了更高的效率和鲁棒性。
+ ORB特征点检测的过程首先利用FAST算法来快速检测图像中的角点。这些角点通常是图像中像素值发生急剧变化的区域，如边缘、角等。为了提高特征点的旋转不变性，ORB算法会对检测到的角点进行方向计算，为每个角点分配一个主方向。接着，ORB算法使用BRIEF描述子算法为每个角点生成一个紧凑的二进制特征向量。这个特征向量仅包含0和1，其顺序根据特定角点和其周围像素区域的灰度强度变化而定。这种二进制特征向量可以节省内存空间和计算时间，同时保持较高的特征匹配准确性。
+ ORB算法在实时视觉应用，如SLAM（同时定位与地图构建）和无人机视觉等领域中得到了广泛应用。它提供了一种有效的方式来从图像中提取和描述关键特征点，以便进行后续的匹配、跟踪和三维重建等任务。
```python
orbimg=input_image.copy()

orb = cv2.ORB_create()

# find the keypoints with ORB

kp = orb.detect(orbimg,None)

# compute the descriptors with ORB

kp, des = orb.compute(orbimg, kp)

# draw keypoints

cv2.drawKeypoints(orbimg,kp,orbimg)

plt.imshow(cv2.cvtColor(orbimg, cv2.COLOR_BGR2RGB))
```
![wps7.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps7.jpg)
+ 与此同时，ORB特征点还具有平移不变性，简单的几何变换不影响ORB特征点的计算与匹配。下例展示了ORB特征点的匹配操作：
```python
kp2 = orb.detect(img2match,None)

# compute the descriptors with ORB

kp2, des2 = orb.compute(img2match, kp2)

# create BFMatcher object: this is a Brute Force matching object

bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

# Match descriptors.

matches = bf.match(des,des2)

# Sort them by distance between matches in feature space - so the best matches are first.

matches = sorted(matches, key = lambda x:x.distance)


# Draw first 50 matches.

oimg = cv2.drawMatches(orbimg,kp,img2match,kp2,matches[:50], orbimg)


plt.imshow(cv2.cvtColor(oimg, cv2.COLOR_BGR2RGB))
```
![wps8.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/wps8.jpg)

### 10.1.3 计算机视觉
[[10 卷积神经网络Convolutional Neural Networks]]
[[4 卷积神经网络]]
[[0 CS231n]]

## 10.2 计算语言学与自然语言处理
### 10.2.1 Python处理字符串
[[1~2 变量和简单数据类型]]

### 10.2.2 文本的嵌入表示
[[自然语言处理基础]]

### 10.2.3 文本的分类与话题模型
[[5 循环神经网络]]
[[14 序列模型-循环神经网络]]
[[0 CS224n]]

## 10.3 数字信号处理与智能感知
### 10.3.1 数字信号的傅里叶变换
### 10.3.2 数字信号的统计指标
### 10.3.3 数字信号的滤波与分解
## 10.4 多模态数据与人工智能
### 10.4.1 多模态概念与意义
### 10.4.2 多模态模型发展关系及时间线
### 10.4.3 Transformer
[[7 Transformer]]

### 10.4.4 多模态任务对齐
#### 文本转Embedding
#### 图像转换Embedding
#### 模态对齐
### 10.4.5 多模态模型训练流程